{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "import tensorflow\n",
    "import gymnasium as gym\n",
    "\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Brain(input_shape, action_shape):\n",
    "    _input = Input(shape=input_shape)\n",
    "    _layer = Dense(512, activation='relu', kernel_initializer='he_uniform')(_input)\n",
    "    _layer = Dense(256, activation='relu', kernel_initializer='he_uniform')(_layer)\n",
    "    _layer = Dense(64, activation='relu', kernel_initializer='he_uniform')(_layer)\n",
    "    _layer = Dense(action_shape, activation='linear', kernel_initializer='he_uniform')(_layer)\n",
    "    _model = Model(inputs=_input, outputs=_layer)\n",
    "    # Note: Optimizer and compile are not strictly needed for inference,\n",
    "    # but load_model might expect them depending on how the model was saved.\n",
    "    # Including them here for compatibility if the saved model includes optimizer state.\n",
    "    _optimizer = RMSprop(learning_rate=0.00025, rho=0.95, epsilon=0.01)\n",
    "    _model.compile(loss='mse', optimizer=_optimizer, metrics=['accuracy'])\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tensorflow.keras.utils.register_keras_serializable(package='custom', name='mse')\n",
    "def mse(y_true, y_pred):\n",
    "    return tensorflow.keras.losses.mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self):\n",
    "        # Path to the saved model file\n",
    "        self.model_name = 'models/cartpole-dqn.h5'\n",
    "\n",
    "        # Environment setup (needed for state/action sizes and running the simulation)\n",
    "        self.env = gym.make('CartPole-v1', render_mode='human') # Use human render mode to visualize\n",
    "        self.state_size = self.env.observation_space.shape[0]\n",
    "        self.action_size = self.env.action_space.n\n",
    "\n",
    "        # Model will be loaded in the run method\n",
    "        self.model = None\n",
    "\n",
    "    def run(self):\n",
    "        # Load the trained model\n",
    "        try:\n",
    "            # Pass custom_objects to load the custom mse function\n",
    "            self.model = load_model(self.model_name, custom_objects={'mse': mse})\n",
    "            print(f\"Model loaded successfully from {self.model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            print(\"Please ensure the model has been trained and saved to the correct path.\")\n",
    "            return\n",
    "\n",
    "        print(\"Running the trained agent...\")\n",
    "        for i in range(25): # Run for 25 episodes\n",
    "            _state, _ = self.env.reset()\n",
    "            _done = False\n",
    "            _lifetime = 0\n",
    "\n",
    "            while not _done:\n",
    "                # The environment rendering is handled by render_mode='human'\n",
    "                # self.env.render() # This line is not needed with render_mode='human'\n",
    "\n",
    "                # Reshape state for model prediction\n",
    "                _state = numpy.reshape(_state, [1, self.state_size])\n",
    "\n",
    "                # Predict the best action using the loaded model\n",
    "                _action = numpy.argmax(self.model.predict(_state, verbose=0)) # verbose=0 to reduce output\n",
    "\n",
    "                # Take the action in the environment\n",
    "                _nxt_state, _reward, terminated, truncated, _info = self.env.step(_action)\n",
    "                _done = terminated or truncated\n",
    "\n",
    "                # Update state\n",
    "                _state = _nxt_state\n",
    "\n",
    "                _lifetime = _lifetime + 1\n",
    "\n",
    "                if _done:\n",
    "                    # Show score and stop the game\n",
    "                    msg = 'Episode: {}, score: {}'\n",
    "                    print(msg.format(i + 1, _lifetime)) # Use i + 1 for 1-based episode numbering\n",
    "                    break\n",
    "\n",
    "        self.env.close() # Close the environment window after running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from models/cartpole-dqn.h5\n",
      "Running the trained agent...\n",
      "Episode: 1, score: 449\n",
      "Episode: 2, score: 451\n",
      "Episode: 3, score: 467\n",
      "Episode: 4, score: 405\n",
      "Episode: 5, score: 451\n",
      "Episode: 6, score: 404\n",
      "Episode: 7, score: 441\n",
      "Episode: 8, score: 434\n",
      "Episode: 9, score: 425\n",
      "Episode: 10, score: 408\n",
      "Episode: 11, score: 435\n",
      "Episode: 12, score: 423\n",
      "Episode: 13, score: 427\n",
      "Episode: 14, score: 410\n",
      "Episode: 15, score: 424\n",
      "Episode: 16, score: 431\n",
      "Episode: 17, score: 455\n",
      "Episode: 18, score: 451\n",
      "Episode: 19, score: 433\n",
      "Episode: 20, score: 443\n",
      "Episode: 21, score: 438\n",
      "Episode: 22, score: 419\n",
      "Episode: 23, score: 437\n",
      "Episode: 24, score: 422\n",
      "Episode: 25, score: 412\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
